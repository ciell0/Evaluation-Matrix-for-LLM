# ğŸš€ SFT Evaluation Framework

**Framework modular untuk melakukan evaluasi model SFT (Supervised Fine-Tuning) secara otomatis**.
Mendukung inference, perhitungan berbagai metrik evaluasi, validasi format output, dan upload hasil ke HuggingFace Hub.

---

# âœ¨ **Fitur Utama**

### âœ… **1. Inference otomatis**

* Generate prediksi model SFT terhadap dataset test
* Support model local path maupun HuggingFace Hub
* Support dataset lokal maupun HuggingFace Dataset

### âœ… **2. Banyak metrik evaluasi**

Semua metrik dieksekusi melalui modular evaluator:

* **Exact Match (EM)**
* **Token F1 Score**
* **ROUGE-L**
* **BERTScore**
* **Embedding Similarity**
* **Format Validity / Rule Checking**

Metrik dapat di-*enable/disable* melalui file YAML konfigurasi.

### âœ… **3. Script modular**

Termasuk script untuk:

* inference
* evaluasi
* upload ke HuggingFace
* experiment pipeline end-to-end

### âœ… **4. Konfigurasi fleksibel**

Semua komponen (model, dataset, inference config, evaluasi config) ditentukan melalui folder `configs/`.

### âœ… **5. Struktur folder bersih dan scalable**

Repository mengikuti standar proyek ML engineering modern.

---

# ğŸ“‚ **Struktur Direktori**

```
your-eval-project/
â”‚
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ eval_config.yaml
â”‚   â”œâ”€â”€ model_config.yaml
â”‚   â””â”€â”€ dataset_config.yaml
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ inference/
â”‚   â”œâ”€â”€ eval/
â”‚   â”œâ”€â”€ utils/
â”‚   â””â”€â”€ uploader/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ test.jsonl
â”‚   â””â”€â”€ predictions.jsonl
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_inference.sh
â”‚   â”œâ”€â”€ run_eval.sh
â”‚   â””â”€â”€ upload_to_hf.sh
â”‚
â”œâ”€â”€ experiment.sh
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

---

# ğŸ”§ **Persiapan Lingkungan**

Repo ini menggunakan **Python 3.10+** dan dependency dikelola menggunakan **uv** atau pip.

## ğŸ“¥ Instalasi menggunakan uv (direkomendasikan)

```bash
uv sync
```

## ğŸ“¥ Instalasi menggunakan pip

```bash
pip install -r requirements.txt
```

---

# ğŸ”Œ **Konfigurasi**

Semua konfigurasi ada dalam folder:

```
configs/
```

### ğŸ§© `model_config.yaml`

Mengatur model yang dipakai untuk inference:

```yaml
model_name: my-sft-model
tokenizer_name: my-sft-model
device: cuda
```

### ğŸ§© `dataset_config.yaml`

Mengatur sumber dataset:

```yaml
dataset_path: data/test.jsonl
```

Bisa juga memakai HuggingFace:

```yaml
dataset_path: hf://username/my-dataset
```

### ğŸ§© `eval_config.yaml`

Menentukan metrik apa saja yang dipakai:

```yaml
metrics:
  exact_match: true
  f1: true
  rouge: true
  bertscore: false
  embed_sim: true
  format_validity: true

generation:
  max_new_tokens: 128
  temperature: 0.7
```

---

# â–¶ï¸ **Menjalankan Proyek**

Ada 3 cara menjalankan pipeline: manual, per step, atau otomatis.

---

## **1. Menjalankan inference**

```bash
bash scripts/run_inference.sh
```

Atau:

```bash
python -m src.inference.run_inference \
  --model_path outputs/my-sft-model \
  --data_path data/test.jsonl \
  --output_path results/predictions.jsonl
```

---

## **2. Menjalankan evaluasi**

```bash
bash scripts/run_eval.sh
```

Atau:

```bash
python -m src.eval.evaluator \
  --pred_path results/predictions.jsonl \
  --gold_path data/test.jsonl \
  --config configs/eval_config.yaml \
  --output_path results/metrics.json
```

---

## **3. Upload ke HuggingFace Hub**

```bash
bash scripts/upload_to_hf.sh
```

---

# ğŸš€ **Menjalankan Pipeline End-to-End**

Jalankan satu perintah:

```bash
bash experiment.sh
```

Pipeline akan menjalankan:

1. inference
2. evaluasi
3. upload hasil

---

# ğŸ“Š **Output Evaluasi**

Hasil evaluasi disimpan di:

```
results/metrics.json
```

Contoh output:

```json
{
  "exact_match": 0.32,
  "f1_score": 0.71,
  "rouge_l": 0.56,
  "embedding_similarity": 0.83,
  "format_validity": 0.92
}
```

---

# ğŸ”§ **Menambah Metrik Baru**

Tambah file baru di:

```
src/eval/
```

Contoh:

```
my_custom_metric.py
```

Daftarkan ke evaluator pada:

```
src/eval/evaluator.py
```

Framework ini memang dibuat untuk memudahkan extend metrik baru.

---
